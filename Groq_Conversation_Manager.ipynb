{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BaMcMGj5P8gp"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai\n",
        "!pip install -q jsonschema"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Imports & API-key loader\n",
        "import openai\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Read the secret that Colab stores for us\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get(\"GROQ_API_KEY\")\n",
        "\n",
        "# Point the client to Groq's endpoint (v1/chat/completions)\n",
        "client = openai.OpenAI(\n",
        "    api_key=openai.api_key,\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Groq client ready ‚Äì base URL set to\", client.base_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWP0vmCRQqbT",
        "outputId": "9af1db8f-e0a9-4c0e-b114-25d6bd4daf0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Groq client ready ‚Äì base URL set to https://api.groq.com/openai/v1/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### ConversationManager (turn limit, char limit, k-run summarisation)\n",
        "class ConversationManager:\n",
        "    def __init__(self,\n",
        "                 turn_limit=None,   # keep last N messages (None = unlimited)\n",
        "                 char_limit=None,   # keep last X chars (None = unlimited)\n",
        "                 k_summarise=3):    # summarise every k-th exchange\n",
        "        self.turn_limit = turn_limit\n",
        "        self.char_limit = char_limit\n",
        "        self.k_summarise = k_summarise\n",
        "        self.history = []          # list of dicts: {\"role\":\"user\"|\"assistant\", \"content\":\"...\"}\n",
        "        self.run_counter = 0       # how many user/assistant pairs we have seen\n",
        "\n",
        "    # --------------- public helpers ---------------\n",
        "    def add_user(self, text):\n",
        "        self.history.append({\"role\": \"user\", \"content\": text})\n",
        "\n",
        "    def add_assistant(self, text):\n",
        "        self.history.append({\"role\": \"assistant\", \"content\": text})\n",
        "        self.run_counter += 1\n",
        "        # periodic summarisation\n",
        "        if self.run_counter % self.k_summarise == 0:\n",
        "            self._summarise_internal()\n",
        "\n",
        "    # --------------- truncation helpers ---------------\n",
        "    def _apply_turn_limit(self):\n",
        "        if self.turn_limit:\n",
        "            # keep last N messages\n",
        "            self.history = self.history[-self.turn_limit:]\n",
        "\n",
        "    def _apply_char_limit(self):\n",
        "        if self.char_limit:\n",
        "            # pop from the top until under limit\n",
        "            while self.history and len(str(self.history)) > self.char_limit:\n",
        "                self.history.pop(0)\n",
        "\n",
        "    # --------------- summarisation ---------------\n",
        "    def _summarise_internal(self):\n",
        "        \"\"\"Ask Groq for a concise summary, replace history with [summary, last_message].\"\"\"\n",
        "        # build a single string of the current history\n",
        "        transcript = \"\\n\".join(f\"{m['role']}: {m['content']}\" for m in self.history)\n",
        "        prompt = (\n",
        "            \"Summarise the following conversation in 2-3 short sentences. \"\n",
        "            \"Retain key facts, names, preferences.\\n\\n\" + transcript\n",
        "        )\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"llama-3.1-8b-instant\",  # any Groq model\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.3,\n",
        "            max_tokens=120\n",
        "        )\n",
        "        summary = response.choices[0].message.content.strip()\n",
        "\n",
        "        # keep the summary + the very last user/assistant pair\n",
        "        last_two = self.history[-2:] if len(self.history) >= 2 else self.history\n",
        "        self.history = [{\"role\": \"system\", \"content\": f\"Summary so far: {summary}\"}] + last_two\n",
        "        print(f\"üìù  Auto-summarised at run #{self.run_counter}\")\n",
        "        print(\"   Summary:\", summary)\n",
        "\n",
        "    # --------------- pretty print ---------------\n",
        "    def show(self):\n",
        "        self._apply_turn_limit()\n",
        "        self._apply_char_limit()\n",
        "        print(\"\\n------ Current history ------\")\n",
        "        for m in self.history:\n",
        "            print(f\"{m['role'].upper()}: {m['content']}\")\n",
        "        print(\"------------------------------\\n\")\n",
        "\n",
        "# quick sanity test\n",
        "cm = ConversationManager()\n",
        "print(\"‚úÖ ConversationManager class defined & tiny test instance created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx7m0NnxRTsZ",
        "outputId": "7cdb3379-4de9-4fd8-9bba-68d82c6d4c79"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ConversationManager class defined & tiny test instance created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Sample chat #1 (3 turns)\n",
        "cm = ConversationManager(turn_limit=None, char_limit=None, k_summarise=3)\n",
        "\n",
        "cm.add_user(\"Hi, my name is Ayaan and I love pizza.\")\n",
        "cm.add_assistant(\"Nice to meet you, Ayaan! What topping do you like most?\")\n",
        "cm.add_user(\"Pepperoni, definitely. I also enjoy hiking on weekends.\")\n",
        "cm.add_assistant(\"Great combo‚Äîpepperoni pizza after a hike! Where do you usually trek?\")\n",
        "cm.add_user(\"Mostly around Lake Tahoe. The views are amazing.\")\n",
        "cm.add_assistant(\"Tahoe is stunning. I hope you get good weather next time!\")\n",
        "\n",
        "cm.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl0kM6GOS5Ea",
        "outputId": "be86b80d-42dc-4efd-f819-cbc9a00a407c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù  Auto-summarised at run #3\n",
            "   Summary: Ayaan, who loves pizza, particularly pepperoni, enjoys hiking on weekends. He usually treks around Lake Tahoe, appreciating its stunning views.\n",
            "\n",
            "------ Current history ------\n",
            "SYSTEM: Summary so far: Ayaan, who loves pizza, particularly pepperoni, enjoys hiking on weekends. He usually treks around Lake Tahoe, appreciating its stunning views.\n",
            "USER: Mostly around Lake Tahoe. The views are amazing.\n",
            "ASSISTANT: Tahoe is stunning. I hope you get good weather next time!\n",
            "------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Turn-limit demo (keep last 3 messages)\n",
        "cm = ConversationManager(turn_limit=3, k_summarise=10)  # no auto-summary yet\n",
        "\n",
        "cm.add_user(\"Turn 1: I like red cars.\")\n",
        "cm.add_assistant(\"Red is a bold choice!\")\n",
        "cm.add_user(\"Turn 2: I also play guitar.\")\n",
        "cm.add_assistant(\"Nice! Acoustic or electric?\")\n",
        "cm.add_user(\"Turn 3: Electric. Mostly rock.\")\n",
        "cm.add_assistant(\"Rock on! Any favourite bands?\")\n",
        "\n",
        "print(\"After 5 messages, keeping only last 3:\")\n",
        "cm.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOSCwIt2UK5K",
        "outputId": "c53223ca-2f7d-4906-d3ff-9611e06a1259"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After 5 messages, keeping only last 3:\n",
            "\n",
            "------ Current history ------\n",
            "ASSISTANT: Nice! Acoustic or electric?\n",
            "USER: Turn 3: Electric. Mostly rock.\n",
            "ASSISTANT: Rock on! Any favourite bands?\n",
            "------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Character-limit demo (max ~200 chars)\n",
        "cm = ConversationManager(char_limit=200, k_summarise=99)  # no auto-summary\n",
        "\n",
        "for i in range(1, 6):\n",
        "    cm.add_user(f\"Short message number {i}\")\n",
        "    cm.add_assistant(f\"Reply number {i}\")\n",
        "\n",
        "print(\"History trimmed to ~200 characters:\")\n",
        "cm.show()\n",
        "print(\"Raw list length:\", len(str(cm.history)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlLSNqOQVKex",
        "outputId": "5ce31371-2e11-41ee-f693-b6b055b0b80f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "History trimmed to ~200 characters:\n",
            "\n",
            "------ Current history ------\n",
            "ASSISTANT: Reply number 4\n",
            "USER: Short message number 5\n",
            "ASSISTANT: Reply number 5\n",
            "------------------------------\n",
            "\n",
            "Raw list length: 159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Combined limits + k=2 summarisation\n",
        "cm = ConversationManager(turn_limit=4, char_limit=300, k_summarise=2)\n",
        "\n",
        "# Turn 1\n",
        "cm.add_user(\"I want to learn Japanese.\")\n",
        "cm.add_assistant(\"Great goal! How much time can you study daily?\")\n",
        "\n",
        "# Turn 2  -> triggers summary (k=2)\n",
        "cm.add_user(\"About 30 min.\")\n",
        "cm.add_assistant(\"Perfect‚Äîconsistency beats cramming.\")\n",
        "\n",
        "# Turn 3\n",
        "cm.add_user(\"Should I start with hiragana?\")\n",
        "cm.add_assistant(\"Absolutely, master hiragana first.\")\n",
        "\n",
        "cm.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB6NJvaTVRyQ",
        "outputId": "cff63c70-dabc-4f37-e996-c6951cfcfa45"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù  Auto-summarised at run #2\n",
            "   Summary: A user expressed their desire to learn Japanese and was advised by an assistant to prioritize consistency over cramming, suggesting that studying 30 minutes daily is a good starting point.\n",
            "\n",
            "------ Current history ------\n",
            "USER: About 30 min.\n",
            "ASSISTANT: Perfect‚Äîconsistency beats cramming.\n",
            "USER: Should I start with hiragana?\n",
            "ASSISTANT: Absolutely, master hiragana first.\n",
            "------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task2: starts here\n",
        "#@markdown ### JSON schema for structured extraction\n",
        "user_schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"name\":    {\"type\": \"string\"},\n",
        "        \"email\":   {\"type\": \"string\"},\n",
        "        \"phone\":   {\"type\": \"string\"},\n",
        "        \"location\":{\"type\": \"string\"},\n",
        "        \"age\":     {\"type\": \"integer\"}\n",
        "    },\n",
        "    \"required\": [\"name\", \"email\", \"phone\", \"location\", \"age\"],\n",
        "    \"additionalProperties\": False\n",
        "}\n",
        "\n",
        "# Wrap it inside the 'function' format OpenAI expects\n",
        "functions = [\n",
        "    {\n",
        "        \"name\": \"extract_user_details\",\n",
        "        \"description\": \"Extract user-supplied personal details from chat.\",\n",
        "        \"parameters\": user_schema\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"‚úÖ Schema defined and wrapped for function-calling.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhpYRC9CVbyg",
        "outputId": "ad246801-bff0-412f-f308-e7840426d65e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Schema defined and wrapped for function-calling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Extraction helper\n",
        "import json\n",
        "\n",
        "def extract_details(chat_text: str):\n",
        "    \"\"\"Return dict with keys: name, email, phone, location, age.\"\"\"\n",
        "    messages = [{\"role\": \"user\", \"content\": chat_text}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=messages,\n",
        "        functions=functions,\n",
        "        function_call={\"name\": \"extract_user_details\"}  # force the call\n",
        "    )\n",
        "    # the LLM reply contains the function call\n",
        "    func_call = response.choices[0].message.function_call\n",
        "    if not func_call or func_call.name != \"extract_user_details\":\n",
        "        raise RuntimeError(\"Function call not returned\")\n",
        "    args = json.loads(func_call.arguments)\n",
        "    return args\n",
        "\n",
        "print(\"‚úÖ extract_details() ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXQdBCFHVpeJ",
        "outputId": "24b4e48d-0bd8-4025-baa9-634e90a7523b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ extract_details() ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Sample chats for extraction\n",
        "samples = [\n",
        "    \"Hey, I'm Alice Smith, 28 years old. You can reach me at alice@example.com or call 415-555-1234. I live in San Francisco.\",\n",
        "    \"My name is Rohan Patel. I'm 35, based in Mumbai. Email: rohan.p@mail.io and phone +91 98765 43210.\",\n",
        "    \"Hi there! Lucy Brown, 22, from London. lucy.brown@uk.net ‚Äì mobile 07911 123456.\"\n",
        "]\n",
        "\n",
        "for idx, chat in enumerate(samples, 1):\n",
        "    print(f\"\\n----- Sample {idx} -----\")\n",
        "    print(\"Input:\", chat)\n",
        "    try:\n",
        "        data = extract_details(chat)\n",
        "        print(\"Extracted JSON:\")\n",
        "        print(json.dumps(data, indent=2))\n",
        "    except Exception as e:\n",
        "        print(\"Extraction failed:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvS3So_jVzeQ",
        "outputId": "d079f822-3d20-4328-cdcc-a607088cb5c1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----- Sample 1 -----\n",
            "Input: Hey, I'm Alice Smith, 28 years old. You can reach me at alice@example.com or call 415-555-1234. I live in San Francisco.\n",
            "Extracted JSON:\n",
            "{\n",
            "  \"age\": 28,\n",
            "  \"email\": \"alice@example.com\",\n",
            "  \"location\": \"San Francisco\",\n",
            "  \"name\": \"Alice Smith\",\n",
            "  \"phone\": \"415-555-1234\"\n",
            "}\n",
            "\n",
            "----- Sample 2 -----\n",
            "Input: My name is Rohan Patel. I'm 35, based in Mumbai. Email: rohan.p@mail.io and phone +91 98765 43210.\n",
            "Extracted JSON:\n",
            "{\n",
            "  \"age\": 35,\n",
            "  \"email\": \"rohan.p@mail.io\",\n",
            "  \"location\": \"Mumbai\",\n",
            "  \"name\": \"Rohan Patel\",\n",
            "  \"phone\": \"+91 98765 43210\"\n",
            "}\n",
            "\n",
            "----- Sample 3 -----\n",
            "Input: Hi there! Lucy Brown, 22, from London. lucy.brown@uk.net ‚Äì mobile 07911 123456.\n",
            "Extracted JSON:\n",
            "{\n",
            "  \"age\": 22,\n",
            "  \"email\": \"lucy.brown@uk.net\",\n",
            "  \"location\": \"London\",\n",
            "  \"name\": \"Lucy Brown\",\n",
            "  \"phone\": \"07911 123456\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Validate extracted data against schema\n",
        "from jsonschema import validate, ValidationError\n",
        "\n",
        "def validate_data(data):\n",
        "    try:\n",
        "        validate(instance=data, schema=user_schema)\n",
        "        return True, None\n",
        "    except ValidationError as ve:\n",
        "        return False, ve.message\n",
        "\n",
        "# re-run extraction + validation for the same samples\n",
        "for idx, chat in enumerate(samples, 1):\n",
        "    data = extract_details(chat)\n",
        "    ok, err = validate_data(data)\n",
        "    print(f\"Sample {idx} valid? {ok}\")\n",
        "    if not ok:\n",
        "        print(\"  Error:\", err)\n",
        "    else:\n",
        "        print(\"  ‚úÖ Passed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDK75iORWLIh",
        "outputId": "b34ad630-92f2-46fe-aae6-50e549030870"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1 valid? True\n",
            "  ‚úÖ Passed\n",
            "Sample 2 valid? True\n",
            "  ‚úÖ Passed\n",
            "Sample 3 valid? True\n",
            "  ‚úÖ Passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "usXMBac3WZV4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}